\chapter{Driver Monitoring}

To Update !
\emph{In this chapter, we propose methods to assess the driver's state of drowsiness and inattention based on face and eyes-status analysis. The chapter  begins with a brief discussion of signs of drowsiness and available methods for detecting them, and it continues with the first proposed method which is based on traditional computer vision techniques followed by the seconde method which is based on deep learning, then we discuss the strengths, weakness, and limitations for each method. The chapter continues with our optimization techniques to improve the performance of these methods in terms of speed, detection rate, and detection accuracy under non-ideal lighting conditions and for noisy images. } %% to edit


\section{Introduction}
A driver-monitoring system is an advanced safety feature that track driver drowsiness or distraction, and to issue a warning or alert to get the driver’s attention back to the task of driving.

Driver-monitoring systems typically use sensors to collect data about the driver and pass these data to a software. The software can then determine whether the driver is blinking more than usual, whether the eyes are narrowing or closing, and whether the head is tilting at an odd angle. It can also determine whether the driver is looking at the road ahead, and whether the driver is actually paying attention or just absent-mindedly staring. [x]


!!!!!!!!!!!!!!!!!!!!!!!!!!!! Into from thesis x about driver monitoring !!!!!!!!!!!!!!!!!!!!!!!!!!!!


\section{Driver Monitoring Technologies}
According to \parencite{DrowsinessDetectionSystem} there are many approaches and measurement technologies to predict driver's behaviors. The most commonly used measurement can be categorized upon the monitoring instrument into : 
\begin{itemize}
	\item Video-based sensors
	\item Physiological signals sensors 
\end{itemize}

\begin{figure}[!h]
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.6\linewidth]{cmsensors}  
  \caption{Video-based sensors (used in this thesis)}
  \label{fig:CamSensors}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.6\linewidth]{phsensors}  
  \caption{physiological signals sensors}
  \label{fig:PhSensors}
\end{subfigure}
\caption{Illustration of difrent Driver monitoring approches}
\label{fig:DifrentMonitoringApproches}
\end{figure}


\subsection{Physiological Signals Sensors}
Physiological signals of the driver are the most accurate solutions, they can be used to measure his vigilance level since these signals originated from human organs such as brain, eyes, muscles, and heart that can indicate the fatigue and alertness level in real-time as depicted in Figure \ref{fig:PhSensors}. Physiological measures can be recorded from different organs that show visible correlation with the wakefulness/drowsiness state of a person. This includes \parencite{DrowsinessDetectionSystem}:

	\begin{itemize}
		\item \textbf{Brain activity},which can be captured by electroencephalography (EEG) or Near Infrared Spectroscopy
(NIRS).
		\item \textbf{Cardiac activity}, monitored through electrocardiography (ECG) and Blood Pressure signals.
		\item \textbf{Ocular activity}, measured by electrooculography (EOG)
	\end{itemize}

\subsection{Video-based sensors}
To determine alertness/drowsiness level of driver as illustrated in Figure \ref{fig:CamSensors}. The behaviour of the driver is mainly monitored through a camera and thus this approach is known as video-based measure. Visible symptoms of fatigue and sleepiness can be observed when driver becomes drowsy through measuring its abnormal behaviours. Research on fatigue and drowsiness detection using driver behavioural monitoring focused on three main measure: \emph{Eyes state}, \emph{Face expression}, and \emph{Head position}.

\subsection{Evaluation}
\emph{The following evaluation and ranking are based on our online search of driver monitoring technologies and we belive that it is not the only evaluation method.}

According to \parencite{DrowsinessDetectionSystem}, physiological sensors make it possible to alert driver at earlier stages of drowsiness and thereby prevent many drastic accidents \parencite{EvaluationOfTechnologies}.  Physiological measures have been shown to be reliable and accurate since they are less impacted by environmental and road conditions and thus may have fewer false positives \parencite{Zilberg2007MethodologyAI}.

On the other hand, video sensors technology is user friendly and can be mounted comfortably in various areas inside a vehicle also,it has the lowest coast. The common limitation is lighting conditions.

\begin{table}[h!]
\centering

\begin{tabular}{ |c c c| } 
\hline
Technology & Video-Based Sensors & Physiological Signals Sensors \\
\hline
Coast & ++ & +\\
Ease of Use & +++ & + \\
Intrusiveness & + & +++ \\
Accuracy & ++ & +++\\
\hline
\end{tabular}
\caption{shows the evaluation results of the two above described Driver Monitoring Technologies. The (+) symbol represents the rating level}
\label{table:DriverMonitoringTEchnologiesEvaluationResult}
\end{table}



\section{Driver Drowsiness}
Feeling sleepy or tired during the day is commonly called drowsiness. Drowsiness can lead to additional symptoms, such as forgetting or falling asleep at inappropriate times, especially in the case of driving because it leads to a car accident.

Drowsiness in general is accompanied by warning signs that differ from one person to another, such as yawning\footnote{yawning is a response to fatigue,  it is characterized by opening up of mouth which is accompanied by a long inspiration, with a brief interruption of ventilation and followed by a short expiration.} or blinking frequently, nodding\footnote{nodding also is a response to fatigue, it is characterized by lower or raising the head slowly and briefly}, drifting off the track, and the most critical sign of drowsiness is closed eyes.\parencite{DrowsinessSigns}

\section{Driver Inattention}
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!




\newpage
\section{Proposed work}
\emph{In this section, we propose methods for detecting driver’s drowsiness and distraction using computer vision techniques discussed in chapter 2 with other algorithms that aim for improve performance and accuracy (ACC), then !!!!!!!! gol beli rah ndiro comparaison w rah ndiro analyse l kol methode w nokhorjo b natija ... (!!!! ahki ela system d'alarme)  }

Before anything, the main goal of this work is to invoke audio-alert when a bad thing happend .. 
!!!!

For the application phase, the driver’s surveillance camera is mounted in front of the driver’s face it can be placed in the areas of the steering wheel or it can be hung on the rearview mirror.



\subsection{method 1 : Haar Cascades}
\emph{Viola-Jones facial detection technique, commonly known as Haar Cascades. This work was done well before the beginning of the era of deep learning. But it’s a great job in comparison with powerful models that can be built with modern deep learning techniques, especially in terms of speed. The algorithm is still used almost everywhere.}\\

Haar Cascades in general is an object detection algorithm uses haar features. Haar Features were not only used to detect faces, but also for eyes, lips, license number plates, etc. \parencite{HaarFeaturesUses}.

For a good detection rate, we need a strong classifier that is trained in using a large set of \emph{positive}\footnote{Positive data points are examples of regions containing a face} and \emph{negative}\footnote{Negative data points are examples of regions that do not contain a face} samples of a face, however, \emph{OpenCV}\footnote{Open Source Computer Vision, is a library of programming functions mainly aimed at real-time computer vision. Originally developed by Intel, it was later supported by Willow Garage then Itseez.} can perform face detection out-of-the-box using a pre-trained Haar cascade that is mean OpenCV's Haar cascade has already picked the best haar-like features for face detection, eyes detection, etc. 

This ensures that we do not need to provide our own positive and negative samples, train our own classifier, or worry about getting the parameters tuned exactly right. Instead, we need to focus on improving speed, accuracy and finding solutions for challenging conditions \parencite{PyImageSearchHaarCascades} \parencite{OpenCvHaarCascades} \parencite{HaarFeaturesUses}.

In the application of this method, we use Haar-like detectors provided by \emph{OpenCv}, a haar-like detector takes as argumments \parencite{OpenCvHaarCascades}:

\begin{itemize}

	\item \textbf{Image}: matrix of the type \emph{CV\_8U} \footnote{CV\_8U is unsigned 8bit pixel, a pixel can have values 0-255, this is the normal range for most image and video formats.} containing an gray-scale image where objects are detected.

	\item \textbf{ScaleFactor}: parameter specifying how much the image size is reduced at each image scale.

	\item \textbf{MinNeighbors}: parameter specifying how many neighbors each candidate rectangle should have to retain it.

	\item \textbf{MinSize}: minimum possible object size. Objects smaller than this are ignored.
	
	\item \textbf{MaxSize}: maximum possible object size. Objects larger than this are ignored.

\end{itemize}

By default a haar-like detector returns 4 values \parencite{OpenCvHaarCascades} x-coordinate, y-coordinate, width(w), height(h) of the detected target object, these 4 values represent 2 spatial points $(x , y)$ and $(\quad x + w ,\quad y + h) $ of the rectangle that contains the object see Figure \ref{fig:bbprincipe}. 

\begin{figure}[!h]
\centering
\includegraphics[width=.5\textwidth]{bbprincipe}
\caption{Illustration of Bounding Box in object detection using haar-like detector}
\label{fig:bbprincipe}
\end{figure}
 
Taking the Figure \ref{fig:bbprincipe} as an example. After a successful object detection, a haar-like detector returns :  $(x,\quad y, \quad w, \quad h) = (20, \quad 40, \quad 40, \quad 40)$ respectively.So, $p1 = (20, \quad 40)$ and $p2 = (20 + 40 , 40 + 40 ) = (60 ,\quad 80)$. However, these bounding boxes are useless in the case of driver monitoring, the most important thing is to alert the driver in real time when he is asleep or distracted.

In the application stage of this method to serve as a driver monitoring technique. we used two Haar-like detectors, the first one is a face detector to check whether a given image contains a face or not, In other words, the face detector can check whether the driver is focusing on the road or distracted. Assuming the camera is in front of the driver’s face, if the face detector finds a face on a given image, This means that the driver looks forward and if the detector cannot find a face that means that the driver is distracted by looking in a direction other than the road, which is a dangerous situation, especially when driving fast. 

The second Haar-like detector is an eye detector, which can find an "open" eye in a given image. Using this condition, the eye detector can check if the driver’s eyes are open or closed, simply by performing an eye detection if the detector finds one or both eyes that means the driver is focusing on the road if not, This means that one or both eyes of the driver are closed and this is the critical sign of driver's drowsiness which requires an alert to wake up the driver.
 
As this method works with images, and the camera feeds the system with a video stream which is basically a sequence of images we processed the video frame by frame, and for each frame, we performed haar cascades see Figure\ref{fig:Initfchc}. 

\begin{figure}[!h]
\centering
\includegraphics[width=.7\textwidth]{Init haarcascades}
\caption{Initial flowchart for driver monitoring with haarcascades}
\label{fig:Initfchc}
\end{figure}

\newpage

 The first implementation of this method was done with the following algorithm under difrent lighting conditions :  
 
 
\begin{algorithm}[!h]
  \caption{first algorithm for face/eyes detection using Haar cascades}
  \begin{itemize}
  	\item Load haar-like detectors provided by OpenCv
  	\item Foreach frame from video input :	
  	\begin{enumerate}	
		\item Change color space from RGB to Gray	
		\item Face detection with following parameters : 
		      \begin{itemize}
		      	\item \textbf{Image} : frame
		      	\item \textbf{ScaleFactor} : 1.1
		      	\item \textbf{MinNeighbors} :  2
		      \end{itemize}	     
		\item Eye detection with following parameters :
			  \begin{itemize}
		      	\item \textbf{Image} : frame
		      	\item \textbf{ScaleFactor} : 1.1
		      	\item \textbf{MinNeighbors} :  2
		      \end{itemize}	
		\item draw bounding boxes on frame
		\item display frame		
  	\end{enumerate}
  \end{itemize}
\end{algorithm}


As expected, the first implementation of face/eyes detection with haar cascades in real-time using a laptop camera was very fast and computation friendly. Despite of the speed, both detectors showed few FPs (Flse positives) see Figure\ref{fig:Fedwhc}.

\begin{figure}[!h]
\centering
\includegraphics[width=.5\textwidth]{f0}
\caption{face/eyes detection with Haar cascades}
\label{fig:Fedwhc}
\end{figure}


Figure \ref{fig:Fedwhcudlc} shows face/eyes detection with haarcascades under non-ideal lighting conditions. So, By applying haar-like detectors for face and eyes detection, we gained time and speed wich allows us to use this method in real-time driver monitoring. However, we also need further improvements, as we still may encounter issues of either missing detections (FNs) or false detections (FPs). In the case of this study FNs does not a serious problem because, in the worst case they only invoke alerts, Unlike FPs. False-positive means the driver is maybe distracted but the system can detect the face/eyes of the driver and this is too dangerous because no alert will be invoked in this case. So, in the optimization section we will focus more on decreasing the (FPs), and improving algorithm robustness under variable lighting conditions.


\begin{figure}[!h]
\centering
  \subcaptionbox{}{\includegraphics[width = 3in]{f1}}\quad
  \subcaptionbox{}{\includegraphics[width = 3in]{f4}}\\
  \subcaptionbox{}{\includegraphics[width = 3in]{f3}}\quad
  \subcaptionbox{}{\includegraphics[width = 3in]{f2}}
  
  \caption{face/eyes detection with Haar cascades under diferent lighting conditions}
\label{fig:Fedwhcudlc}
\end{figure}


\subsubsection{Problems and limitations}

Haar cascades are notoriously prone to false-positives, the Haar-like classifier can easily report a face in an image when no face is present under normal lighting conditions, eye classifier is worse in false detection because there are many parts of face have the same color and shape property of the eyes for example the \emph{Oral commissure}\footnote{The commissure is the corner of the mouth, where the vermillion border of the superior labium (upper lip) meets that of the inferior labium (lower lip).}. The situation becomes even more complicated when a part of the driver's face is brighter than the other part (due to light falling in through a side-window), making eye status detection extremely difficult. In addition to that we noticed that sometimes the performance drops dramaticaly after a while due to 
the big number of computations per frame.

Another important thing to note here , along the testing of this method we found a problem which is sometimes a face or an eye can be detected 2 times in the same instance. this situation apears generraly when trying to approach the camera, sudenly a bounding box apears in the screen including both the object (face / eye ), and the other bounding box.


In the next section we propose few methods to tackle the above issues which mainly summarized in :

\begin{itemize}

\item False positives for both face and eyes

\item double detection, this problem is when an object has been detected two times in the same instance

\item detection fails under bad lighting conditions

\end{itemize}


\subsubsection{Optimization}









